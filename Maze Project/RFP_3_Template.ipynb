{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdb73e9d",
   "metadata": {},
   "source": [
    "# RFP: Maze Solvers\n",
    "\n",
    "## Project Overview\n",
    "You are invited to submit a proposal that answers the following question:\n",
    "\n",
    "### What path will your elf take?\n",
    "\n",
    "*Please submit your proposal by **2/11/25 at 11:59 PM**.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88b6a60",
   "metadata": {},
   "source": [
    "## Required Proposal Components\n",
    "\n",
    "### 1. Data Description\n",
    "In the code cell below, use [Gymnasium](https://gymnasium.farama.org/) to set up a [Frozen Lake maze](https://gymnasium.farama.org/environments/toy_text/frozen_lake/) for your project. When you are done with the set up, describe the reward system you plan on using.\n",
    "\n",
    "*Note, a level 5 maze is at least 10 x 10 cells large and contains at least five lake cells.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8744bf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.envs.toy_text.frozen_lake import generate_random_map\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88c38bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_size = 10\n",
    "map_type = generate_random_map\n",
    "# Make maze\n",
    "\n",
    "env = gym.make('FrozenLake-v1', desc=map_type(size=map_size), render_mode='human', is_slippery=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5e45102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Up</th>\n",
       "      <th>Down</th>\n",
       "      <th>Left</th>\n",
       "      <th>Right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Up  Down  Left  Right\n",
       "0   0     0     0      0\n",
       "1   0     0     0      0\n",
       "2   0     0     0      0\n",
       "3   0     0     0      0\n",
       "4   0     0     0      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Learning Rate - 0.5, discount rate - 0.5\n",
    "#Bellmann Equation = (1-Alpha)q(s,a) + alpha(reward + gamma(max(q(s',a')))\n",
    "\n",
    "#Q Table Diagram\n",
    "#       Up      Down     Right    Left\n",
    "#0\n",
    "#1\n",
    "#2\n",
    "#3\n",
    "#4...\n",
    "\n",
    "qtable = {\n",
    "    \"Up\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "    \"Down\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0], \n",
    "    \"Left\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],  \n",
    "    \"Right\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "}\n",
    "df = pd.DataFrame(qtable)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34314a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0 0.0 False False\n",
      "3\n",
      "1 0.0 True False\n",
      "2\n",
      "1 0.0 True False\n",
      "0\n",
      "10 0.0 False False\n",
      "1\n",
      "20 0.0 False False\n",
      "0\n",
      "10 0.0 False False\n",
      "1\n",
      "20 0.0 False False\n",
      "1\n",
      "20 0.0 False False\n",
      "0\n",
      "10 0.0 False False\n",
      "3\n",
      "10 0.0 False False\n",
      "3\n",
      "11 0.0 False False\n",
      "2\n",
      "21 0.0 False False\n",
      "0\n",
      "31 0.0 False False\n",
      "2\n",
      "21 0.0 False False\n",
      "2\n",
      "22 0.0 False False\n",
      "2\n",
      "32 0.0 False False\n",
      "0\n",
      "31 0.0 False False\n",
      "2\n",
      "21 0.0 False False\n",
      "2\n",
      "11 0.0 False False\n",
      "3\n",
      "10 0.0 False False\n",
      "3\n",
      "11 0.0 False False\n",
      "1\n",
      "12 0.0 True False\n",
      "1\n",
      "10 0.0 False False\n",
      "2\n",
      "11 0.0 False False\n",
      "2\n",
      "1 0.0 True False\n",
      "0\n",
      "0 0.0 False False\n",
      "0\n",
      "0 0.0 False False\n",
      "1\n",
      "0 0.0 False False\n",
      "1\n",
      "0 0.0 False False\n",
      "3\n",
      "1 0.0 True False\n",
      "3\n",
      "1 0.0 True False\n",
      "1\n",
      "10 0.0 False False\n",
      "1\n",
      "10 0.0 False False\n",
      "2\n",
      "11 0.0 False False\n",
      "2\n",
      "21 0.0 False False\n",
      "0\n",
      "20 0.0 False False\n",
      "3\n",
      "21 0.0 False False\n",
      "0\n",
      "20 0.0 False False\n",
      "3\n",
      "20 0.0 False False\n",
      "0\n",
      "30 0.0 False False\n",
      "2\n",
      "40 0.0 False False\n",
      "2\n",
      "30 0.0 False False\n",
      "3\n",
      "20 0.0 False False\n",
      "0\n",
      "10 0.0 False False\n",
      "1\n",
      "10 0.0 False False\n",
      "1\n",
      "20 0.0 False False\n",
      "0\n",
      "30 0.0 False False\n",
      "3\n",
      "20 0.0 False False\n",
      "1\n",
      "21 0.0 False False\n",
      "2\n",
      "22 0.0 False False\n",
      "0\n",
      "32 0.0 False False\n",
      "3\n",
      "31 0.0 False False\n",
      "0\n",
      "21 0.0 False False\n",
      "2\n",
      "31 0.0 False False\n",
      "1\n",
      "41 0.0 False False\n",
      "2\n",
      "51 0.0 False False\n",
      "2\n",
      "41 0.0 False False\n",
      "3\n",
      "42 0.0 False False\n",
      "2\n",
      "52 0.0 True False\n",
      "3\n",
      "0 0.0 False False\n",
      "3\n",
      "0 0.0 False False\n",
      "2\n",
      "10 0.0 False False\n",
      "3\n",
      "11 0.0 False False\n",
      "3\n",
      "12 0.0 True False\n",
      "0\n",
      "0 0.0 False False\n",
      "0\n",
      "10 0.0 False False\n",
      "2\n",
      "11 0.0 False False\n",
      "2\n",
      "1 0.0 True False\n",
      "3\n",
      "1 0.0 True False\n"
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "\n",
    "for _ in range(episodes):\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = env.action_space.sample()\n",
    "        print(action)\n",
    "        next_state, reward, done, truncated, _ = env.step(action)\n",
    "        print(next_state, reward, done, truncated)\n",
    "\n",
    "\n",
    "env.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8119299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.9 #learning rate How much the current q value matches the old q value\n",
    "gamma = 0.1 #discount rate How much we value future rewards\n",
    "\n",
    "def qvalue(state, action, reward, next_state, done):\n",
    "    qvalue = ((1-alpha)*qtable[state][action] + alpha*(reward + gamma*max(qtable[next_state])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38ed9f9",
   "metadata": {},
   "source": [
    "#### The reward system is as follows: Goal = +100,000, Frozen Lake = -1, Hole = -100,000,000. This will incentivize finding the most optimal path towards a goal. However, if an agent enters into a hole, said agent will be nuked from existence.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f80b3f",
   "metadata": {},
   "source": [
    "### 2. Training Your Model\n",
    "In the cell seen below, write the code you need to train a Q-Learning model. Display your final Q-table once you are done training your model.\n",
    "\n",
    "*Note, level 5 work uses only the standard Python library and Pandas to train your Q-Learning model. A level 4 uses external libraries like Baseline3.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86095270",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32204\\1109556065.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;31m#learning rate How much the current q value matches the old q value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mgamma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;31m#discount rate How much we value future rewards\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mq_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mqtable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreward\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqtable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "#Bellman Equation\n",
    "alpha = 0.9 #learning rate How much the current q value matches the old q value\n",
    "gamma = 0.1 #discount rate How much we value future rewards\n",
    "q_value = ((1-alpha)*qtable[state][action] + alpha*(reward + gamma*max(qtable[next_state])))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b912364",
   "metadata": {},
   "source": [
    "### 3. Testing Your Model\n",
    "In the cell seen below, write the code you need to test your Q-Learning model for **1000 episodes**. It is important to test your model for 1000 episodes so that we are all able to compare our results.\n",
    "\n",
    "*Note, level 5 testing uses both a success rate and an average steps taken metric to evaluate your model. Level 4 uses one or the other.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30cf1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e7e09e",
   "metadata": {},
   "source": [
    "### 4. Final Answer\n",
    "In the first cell below, describe the path your elf takes to get to the gift. *Note, a level 5 answer includes a gif of the path your elf takes in order to reach the gift.*\n",
    "\n",
    "In the second cell seen below, describe how well your Q-Learning model performed. Make sure that you explicitly name the **learning rate**, **the discount factor**, and the **reward system** that you used when training your final model. *Note, a level 5 description describes the model's performance using two types of quantitative evidence.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6eef8e",
   "metadata": {},
   "source": [
    "![example image](https://gymnasium.farama.org/_images/frozen_lake.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fdae15",
   "metadata": {},
   "source": [
    "#### Describe the path your elf takes here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8f66ed",
   "metadata": {},
   "source": [
    "#### Describe how well your Q-Learning model performed here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
