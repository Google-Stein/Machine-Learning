{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Final Q-Table =====\n",
      "\n",
      "          Up      Down      Left     Right\n",
      "0  -0.039192 -0.027097 -0.036999 -0.027689\n",
      "1  -0.002104 -0.022472 -0.025894 -0.019738\n",
      "2   0.000000  0.000000  0.000000  0.000000\n",
      "3  -0.009819 -0.000191 -0.006346 -0.009994\n",
      "4   0.000000  0.000000  0.000000  0.000000\n",
      "..       ...       ...       ...       ...\n",
      "95  0.339831  0.050283  0.348401  0.434945\n",
      "96  0.586170  0.431321  0.393032  0.408765\n",
      "97  0.533845  0.468668  0.530606  0.614709\n",
      "98  0.562727  0.987776  0.633597  0.722028\n",
      "99  0.000000  0.000000  0.000000  0.000000\n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.envs.toy_text.frozen_lake import generate_random_map\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Initialize FrozenLake environment\n",
    "map_size = 10\n",
    "map_type = generate_random_map\n",
    "# Make maze\n",
    "\n",
    "env = gym.make('FrozenLake-v1', desc=map_type(size=map_size), is_slippery=True)\n",
    "\n",
    "# Initialize Q-table (100 states for a 4x4 grid)\n",
    "qtable = {\"Up\": [0] * 100, \"Down\": [0] * 100, \"Left\": [0] * 100, \"Right\": [0] * 100}\n",
    "\n",
    "# Hyperparameters\n",
    "alpha = 0.9  # Increased Learning Rate\n",
    "gamma = 0.9  # Discount Factor\n",
    "epsilon = 0.6  # More Exploration\n",
    "episodes = 50000  # Training Episodes\n",
    "\n",
    "# Action mapping\n",
    "actions = {0: \"Left\", 1: \"Down\", 2: \"Right\", 3: \"Up\"}\n",
    "\n",
    "# Training loop\n",
    "for episode in range(episodes):\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        # Epsilon-greedy strategy\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            action = env.action_space.sample()  # Explore (random action)\n",
    "        else:\n",
    "            # Choose the action with the highest Q-value, breaking ties randomly\n",
    "            max_q = max(qtable[a][state] for a in qtable)\n",
    "            best_actions = [a for a in qtable if abs(qtable[a][state] - max_q) < 1e-6]\n",
    "            action_name = random.choice(best_actions)  # Random tie-breaking\n",
    "            action = list(actions.keys())[list(actions.values()).index(action_name)]  # Convert to action index\n",
    "\n",
    "        # Take action and observe results\n",
    "        next_state, reward, done, truncated, _ = env.step(action)\n",
    "\n",
    "        # Small penalty for movement to prevent getting stuck in loops\n",
    "        if reward == 0 and not done:\n",
    "            reward = -0.01  # Slight penalty for taking unnecessary steps\n",
    "\n",
    "        # Q-learning update\n",
    "        action_name = actions[action]\n",
    "        old_value = qtable[action_name][state]\n",
    "        next_max = max(qtable[a][next_state] for a in qtable) if next_state < 100 else 0\n",
    "\n",
    "        qtable[action_name][state] = old_value + alpha * (reward + gamma * next_max - old_value)\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "env.close()\n",
    "\n",
    "# Convert Q-table to DataFrame and Print\n",
    "df = pd.DataFrame(qtable)\n",
    "print(\"\\n===== Final Q-Table =====\\n\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
